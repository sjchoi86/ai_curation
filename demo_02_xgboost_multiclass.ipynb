{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "broadband-logan",
   "metadata": {},
   "source": [
    "# Multi-Class classification with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "organized-canada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages loaded.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_wine\n",
    "print (\"Packages loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-pledge",
   "metadata": {},
   "source": [
    "### Load wine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tropical-flight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:(178, 13) Y:(178,)\n",
      "class_names:['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "data = load_wine()\n",
    "X,Y,class_names = data.data,data.target,data.target_names\n",
    "print (\"X:%s Y:%s\"%(X.shape,Y.shape))\n",
    "print (\"class_names:%s\"%(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "treated-marijuana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
      " ...\n",
      " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
      " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
      " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print (X)\n",
    "print (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-substitute",
   "metadata": {},
   "source": [
    "### Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "general-plenty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:(119, 13) X_test:(59, 13)\n"
     ]
    }
   ],
   "source": [
    "seed = 1 # random seed\n",
    "test_size = 0.33\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(\n",
    "    X, Y, test_size=test_size, random_state=seed)\n",
    "print (\"X_train:%s X_test:%s\"%(X_train.shape,X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-leonard",
   "metadata": {},
   "source": [
    "### Fit XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "empty-detroit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train done.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
      "              gamma=0, gpu_id=-1, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=16,\n",
      "              num_class=3, num_parallel_tree=1, objective='multi:softprob',\n",
      "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "              subsample=1, tree_method='exact', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(\n",
    "    num_class=3,\n",
    "    use_label_encoder=False,\n",
    "    max_depth=6,\n",
    "    objective='multi:softmax',\n",
    "    eval_metric='mlogloss')\n",
    "ret = model.fit(X_train,Y_train)\n",
    "print (\"Train done.\")\n",
    "print (ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-mining",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "directed-tulsa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.61%\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in Y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-punishment",
   "metadata": {},
   "source": [
    "### Hyper-parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "above-scottish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta:[0.1] max_depth:[2] => accuracy: 98.31%\n",
      "eta:[0.1] max_depth:[3] => accuracy: 96.61%\n",
      "eta:[0.1] max_depth:[4] => accuracy: 96.61%\n",
      "eta:[0.1] max_depth:[5] => accuracy: 96.61%\n",
      "eta:[0.1] max_depth:[6] => accuracy: 96.61%\n",
      "eta:[0.3] max_depth:[2] => accuracy: 98.31%\n",
      "eta:[0.3] max_depth:[3] => accuracy: 96.61%\n",
      "eta:[0.3] max_depth:[4] => accuracy: 96.61%\n",
      "eta:[0.3] max_depth:[5] => accuracy: 96.61%\n",
      "eta:[0.3] max_depth:[6] => accuracy: 96.61%\n",
      "eta:[0.5] max_depth:[2] => accuracy: 98.31%\n",
      "eta:[0.5] max_depth:[3] => accuracy: 96.61%\n",
      "eta:[0.5] max_depth:[4] => accuracy: 96.61%\n",
      "eta:[0.5] max_depth:[5] => accuracy: 96.61%\n",
      "eta:[0.5] max_depth:[6] => accuracy: 96.61%\n"
     ]
    }
   ],
   "source": [
    "etas =[0.1,0.3,0.5] # step size shrinkage\n",
    "max_depths = [2,3,4,5,6] # maximum depth of a tree\n",
    "for eta in etas:\n",
    "    for max_depth in max_depths:\n",
    "        model = XGBClassifier(\n",
    "            num_class=3,\n",
    "            use_label_encoder=False,\n",
    "            eta=eta,\n",
    "            max_depth=max_depth,\n",
    "            objective='multi:softmax',\n",
    "            eval_metric='mlogloss')\n",
    "        ret = model.fit(X_train,Y_train) # train\n",
    "        Y_pred = model.predict(X_test) # test\n",
    "        predictions = [round(value) for value in Y_pred] \n",
    "        accuracy = accuracy_score(Y_test, predictions)\n",
    "        print(\"eta:[%.1f] max_depth:[%d] => accuracy: %.2f%%\" % \n",
    "              (eta,max_depth,accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-montgomery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
